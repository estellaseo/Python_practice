# -*- coding: utf-8 -*-

# [ 확률 기반 알고리즘]
# 1. 지도학습 : 나이브 베이즈 모델
# 2. 비지도학습 : 연관분석



# [ 나이브 베이즈 모델 ]
# text data의 분류, 문자 분류, 스팸 여부 등 확인 사용(텍스트 데이터 분석)
# 조건부 확률(ex. 대출이라는 단어가 포함되어 있을 때 스팸, 햄의 확률 계산)을 사용하여 분류
# 계산이 간단, 빠름




#[ 연습 문제 ]
# 희귀병 검사 > 병에 걸린 사람을 D, 양성 판정을 받은 사람을 P
# 병에 걸렸을 경우 양성 판정이 나올 확률 P(P|D) : 0.95
#                                   P(P|Dᶜ) : 0.05
# 전체 인구 중 실제 병에 걸릴 확률 P(D) : 0.001

# P(P) = ?
# P(D) = 0.001
# P(Dᶜ) = 1 - 0.001 = 0.999

# 양성 판정이 나왔을 때(P), 실제 병에 걸렸을 확률(D) 
# P(D|P) = P(P|D)*P(D) / P(P)
#        = P(P|D)*P(D) / (P(P|D)*P(D) + P(P|Dᶜ)*P(Dᶜ))




# [ 인공 신경망  - Deep Learning ]
# AI > 머신러닝(기계학습) > 지도학습 > 딥러닝

# AI > 머신러닝(기계학습)
#    > 딥러닝

# 활성함수
# 신경망 구성 요소

# 퍼셉트론
# 1세대 등장 이론

# AND 연산 : 입력값(X, Y)이 모두 1이면 1 리턴, 그 외 0 리턴
# OR 연산 : 입력값(X, Y)이 모두 0이면 0 리턴, 그 외 1 리턴
# XOR  연산 : 입력값(X, Y)이 모두 같으면 0, 서로 다르면 1 리턴












